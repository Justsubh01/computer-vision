{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Table of content\n\n*  Import utilities.\n\n*  [Augmentation](#Augmentation).\n\n*  [Using pretrained model](#Using-pretrained-model.).\n\n* [Train the parameters for our model](#Train-model).\n\n* [Plot graph between training loss and validation loss](#Plot-graph-between-training-loss-and-validation-loss)\n\n* [Load saved parameters](#Load-saved-parameters).\n\n* [Image Predictions](#Image-Predictions)","metadata":{}},{"cell_type":"markdown","source":"## Import utilities","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms  \nimport torchvision\nimport os\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport cv2\nimport pandas as pd\nimport torchvision.transforms as transforms \nfrom torchvision.transforms import ToTensor,Normalize, RandomHorizontalFlip, Resize\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.autograd import Variable","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir_Train = \"/kaggle/input/intel-image-classification/seg_train\"\ndata_dir_Test = \"/kaggle/input/intel-image-classification/seg_test\"\ndata_dir_pred = \"/kaggle/input/intel-image-classification/seg_pred/seg_pred\"\n\ntrain_dir = data_dir_Train + \"/seg_train\"\nvalid_dir = data_dir_Test + \"/seg_test/\"\npred_files = [os.path.join(data_dir_pred, f) for f in os.listdir(data_dir_pred)]\n\noutcomes = os.listdir(train_dir)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# printing the all outcomes\nprint(outcomes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Augmentation","metadata":{}},{"cell_type":"code","source":"# convert data to a normalized torch.FloatTensor\ntransform = torchvision.transforms.Compose([\n    transforms.Resize((150,150)),\n    transforms.RandomHorizontalFlip(p=0.5), # randomly flip and rotate\n    transforms.ColorJitter(0.3,0.4,0.4,0.2),\n    transforms.ToTensor(),\n    transforms.Normalize((0.425, 0.415, 0.405), (0.205, 0.205, 0.205))\n    ])\n\n# Augmentation on test images not needed\ntransform_tests = torchvision.transforms.Compose([\n    transforms.Resize((150,150)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.425, 0.415, 0.405), (0.255, 0.245, 0.235))\n    ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ImageFloder function uses for make dataset by passing dir adderess as an argument\ntrain_data = torchvision.datasets.ImageFolder(root=train_dir,transform=transform)\ntest_data = torchvision.datasets.ImageFolder(root=valid_dir,transform=transform_tests)\n\n\nvalid_size = 0.15\n# Splot data into train and validation set\nnum_train = len(train_data)\nindices = list(range(num_train))\nnp.random.shuffle(indices)\nsplit = int(np.floor(valid_size * num_train))\ntrain_idx, valid_idx = indices[split:], indices[:split]\n\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_data,batch_size=50,sampler=train_sampler,num_workers=2)\nvalid_loader = DataLoader(train_data, batch_size =100, sampler=valid_sampler, num_workers=3)\ntest_loader= DataLoader(test_data,batch_size=32,shuffle=False,num_workers=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check if cuda is available\ntrain_on_gpu = torch.cuda.is_available()\n\ndevice =  torch.device('cuda' if torch.cuda.is_available else 'cpu')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Using pretrained model.","metadata":{}},{"cell_type":"code","source":"# We will using wide_resnet50_2 for this you can use any model you want\nimport torchvision\nmodel = torchvision.models.wide_resnet50_2(pretrained=True)\n\nfor param in model.parameters():\n    param.required_grad = False\n\n\nnum_ftrt = model.fc.in_features\n\nmodel.fc = nn.Linear(num_ftrt,6)\nmodel.to(device)\nmodel\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"code","source":"# Specify loss function and optimizer\nimport torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\n\n# specify optimizer\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)\nscheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[4,6], gamma=0.06)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train model","metadata":{}},{"cell_type":"code","source":"# number of epochs for training set\nepochs = 7\n\n# track change in validation loss\nvalid_loss_min = np.Inf\nval_loss = []\ntn_loss = []\nfor epoch in range(1,epochs+1):\n\n    # keep track of training and validation loss\n    train_loss = 0.0\n    valid_loss = 0.0\n\n    # Train the model\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):       \n        # move tensor to gpu if cuda is available\n        if train_on_gpu:\n            data, target = data.to(device), target.to(device)\n        # clear the gradiant of all optimizer variable\n        optimizer.zero_grad()\n        # forward pass: compute pradictions by passing inputs\n        output = model(data)\n        # calculate batch loss\n        loss = criterion(output, target)\n        # backward pass: compute gradiant of the loss with respect to the parameters\n        loss.backward()\n        # update parameters by optimizing single step\n        optimizer.step()\n        \n        # update training loss\n        train_loss += loss.item()*data.size(0)\n\n    # validate the model\n\n    model.eval()\n    for batch_idx, (data, target) in enumerate(valid_loader):\n        # move tensor to gpu\n        if train_on_gpu:\n            data, target = data.to(device), target.to(device)\n        # forward pass: compute the validation predictions\n        output = model(data)\n        # calculate the loss\n        loss = criterion(output, target)\n        # update the validation loss \n        valid_loss += loss.item()*data.size(0)\n    \n    # calculate average loss\n    train_loss = train_loss/len(train_loader.sampler)\n    valid_loss = valid_loss/len(valid_loader.sampler)\n    val_loss.append(valid_loss)\n    tn_loss.append(train_loss)\n    # update learning rate\n    scheduler.step()\n    # Print the train and validation loss statistic\n    print('Epoch: {} \\t Training Loss: {:.3f} \\t Validation Loss: {:.3f}'.format(epoch, train_loss, valid_loss))\n    \n    # save model if validation loss decrease\n    if valid_loss <= valid_loss_min:\n        print(\"Validation loss decreased {:.4f}--->{:.4f}  Saving model...\".format(valid_loss_min, valid_loss))\n        # save current model\n        torch.save(model.state_dict(), 'model_state.pt')\n        valid_loss_min = valid_loss\n    print('Learning Rate ------------->{:.4f}'.format(optimizer.state_dict()['param_groups'][0]['lr']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"# Plot graph between training loss and validation loss","metadata":{}},{"cell_type":"code","source":"plt.plot(tn_loss, label='Training loss')\nplt.plot(val_loss, label='Validation loss')\nplt.legend(frameon=False)\n\n\nplt.show()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load saved parameters ","metadata":{}},{"cell_type":"code","source":"# Load model state dict\nmodel.load_state_dict(torch.load('model_state.pt'))\nmodel.eval()\nmodel.cuda()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"----","metadata":{}},{"cell_type":"markdown","source":"# Predictions on test dataset","metadata":{}},{"cell_type":"code","source":"correct_count, all_count = 0,0\nfor images, labels in test_loader:\n    for i in range(len(labels)):\n        if torch.cuda.is_available():\n            images = images.cuda()\n            labels = labels.cuda()\n        img = images[i].view(1,3,150,150)\n        with torch.no_grad():\n            logps = model(img)\n            \n        ps = torch.exp(logps)\n        probab = list(ps.cpu()[0])\n        pred_label = probab.index(max(probab))\n        true_label = labels.cpu()[i]\n        if(true_label == pred_label):\n            correct_count += 1\n        all_count += 1\n        \nprint(\"Number of images Tested=\", all_count)\nprint(\"\\n Model Accuracy=\",(correct_count/all_count)*100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Image Predictions","metadata":{}},{"cell_type":"code","source":"def pred_class(img):\n    # transform images\n    img_tens = transform_tests(img)\n    # change image format (3,150,150) to (1,3,150,150) by help of unsqueeze function\n    # image needs to be in cuda before predition\n    img_im = img_tens.unsqueeze(0).cuda() \n    uinput = Variable(img_im)\n    uinput = uinput.to(device)\n    out = model(uinput)\n    # convert image to numpy format in cpu and snatching max prediction score class index\n    index = out.data.cpu().numpy().argmax()    \n    return index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make class dictionary so i can grab class name by index(key)\nclasses = {k:v for k , v in enumerate(sorted(outcomes))}\nmodel.eval()\n\n\nplt.figure(figsize=(20,20))\nfor i, images in enumerate(pred_files):\n    # just want 25 images to print\n    if i > 24:break\n    img = Image.open(images)\n    index = pred_class(img)\n    plt.subplot(5,5,i+1)\n    plt.title(classes[index])\n    plt.axis('off')\n    plt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"--------","metadata":{}},{"cell_type":"markdown","source":"-------","metadata":{}},{"cell_type":"markdown","source":"![Upvote](https://tenor.com/view/the-end-end-waving-bye-goodbye-gif-16288632.gif)","metadata":{}},{"cell_type":"markdown","source":"# Consider a upvote if you have come this far..","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}